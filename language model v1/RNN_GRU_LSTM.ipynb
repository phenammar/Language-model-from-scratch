{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Language Model"
      ],
      "metadata": {
        "id": "EeYX3-crXoZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `imports`"
      ],
      "metadata": {
        "id": "9AyVxJSfYAzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, LSTM, GRU, Bidirectional\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "rIG90FjLYPIk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consants\n",
        "\n",
        "VOCAB_SIZE = 20000\n",
        "SEQ_LEN = 10\n",
        "EMBED_DIM = 128\n",
        "max_length = 300\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 256\n"
      ],
      "metadata": {
        "id": "v_v0b52NnPcH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Load dataset`"
      ],
      "metadata": {
        "id": "XfAOif4zZmCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data\n",
        "!wget -O data/wiki.train.raw https://raw.githubusercontent.com/pytorch/examples/main/word_language_model/data/wikitext-2/train.txt\n",
        "!wget -O data/wiki.valid.raw https://raw.githubusercontent.com/pytorch/examples/main/word_language_model/data/wikitext-2/valid.txt\n",
        "!wget -O data/wiki.test.raw https://raw.githubusercontent.com/pytorch/examples/main/word_language_model/data/wikitext-2/test.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdxN6zrDbgOI",
        "outputId": "d42cf11e-f041-414e-c652-0e85ca2639a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-29 11:08:58--  https://raw.githubusercontent.com/pytorch/examples/main/word_language_model/data/wikitext-2/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10797148 (10M) [text/plain]\n",
            "Saving to: ‘data/wiki.train.raw’\n",
            "\n",
            "data/wiki.train.raw 100%[===================>]  10.30M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2026-01-29 11:08:59 (71.7 MB/s) - ‘data/wiki.train.raw’ saved [10797148/10797148]\n",
            "\n",
            "--2026-01-29 11:08:59--  https://raw.githubusercontent.com/pytorch/examples/main/word_language_model/data/wikitext-2/valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1121681 (1.1M) [text/plain]\n",
            "Saving to: ‘data/wiki.valid.raw’\n",
            "\n",
            "data/wiki.valid.raw 100%[===================>]   1.07M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2026-01-29 11:09:00 (116 MB/s) - ‘data/wiki.valid.raw’ saved [1121681/1121681]\n",
            "\n",
            "--2026-01-29 11:09:00--  https://raw.githubusercontent.com/pytorch/examples/main/word_language_model/data/wikitext-2/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1256449 (1.2M) [text/plain]\n",
            "Saving to: ‘data/wiki.test.raw’\n",
            "\n",
            "data/wiki.test.raw  100%[===================>]   1.20M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2026-01-29 11:09:00 (96.9 MB/s) - ‘data/wiki.test.raw’ saved [1256449/1256449]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb-Vyp8icjVQ",
        "outputId": "4a2efe82-b984-49f6-affa-4822f0aeeb64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wiki.test.raw  wiki.train.raw  wiki.valid.raw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train data\n",
        "with open(\"data/wiki.train.raw\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_texts = f.read().split(\"\\n\")\n",
        "\n",
        "train_texts = [t for t in train_texts if len(t.strip()) > 0]\n",
        "\n",
        "\n",
        "\n",
        "# test data\n",
        "with open(\"data/wiki.test.raw\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_texts = f.read().split(\"\\n\")\n",
        "\n",
        "test_texts = [t for t in test_texts if len(t.strip()) > 0]\n",
        "\n",
        "\n",
        "\n",
        "# valid data\n",
        "with open(\"data/wiki.valid.raw\", \"r\", encoding=\"utf-8\") as f:\n",
        "    valid_texts = f.read().split(\"\\n\")\n",
        "\n",
        "valid_texts = [t for t in valid_texts if len(t.strip()) > 0]\n",
        "\n",
        "# show samples\n",
        "print(len(train_texts))\n",
        "print(train_texts[:5])\n",
        "print(\"==================================================\")\n",
        "print(len(test_texts))\n",
        "print(test_texts[:5])\n",
        "print(\"==================================================\")\n",
        "print(len(valid_texts))\n",
        "print(valid_texts[:5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGrUilyKcO3-",
        "outputId": "7530455b-e26c-4511-d63a-948bbaaaf213"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23767\n",
            "[' = Valkyria Chronicles III = ', ' Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . <unk> the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . ', \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more <unk> for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \", \" It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \", ' = = Gameplay = = ']\n",
            "==================================================\n",
            "2891\n",
            "[' = Robert <unk> = ', ' Robert <unk> is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John <unk> in 2002 . In 2004 <unk> landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the <unk> <unk> Factory in London . He was directed by John <unk> and starred alongside Ben <unk> , Shane <unk> , Harry Kent , Fraser <unk> , Sophie Stanton and Dominic Hall . ', ' In 2006 , <unk> starred alongside <unk> in the play <unk> written by Mark <unk> . He appeared on a 2006 episode of the television series , Doctors , followed by a role in the 2007 theatre production of How to Curse directed by <unk> <unk> . How to Curse was performed at Bush Theatre in the London Borough of <unk> and Fulham . <unk> starred in two films in 2008 , <unk> <unk> by filmmaker Paris <unk> , and <unk> Punch directed by <unk> Blackburn . In May 2008 , <unk> made a guest appearance on a two @-@ part episode arc of the television series Waking the Dead , followed by an appearance on the television series <unk> in November 2008 . He had a recurring role in ten episodes of the television series <unk> in 2010 , as \" <unk> Fletcher \" . <unk> starred in the 2011 film <unk> directed by Paris <unk> . ', ' = = Career = = ', ' = = = 2000 – 2005 = = = ']\n",
            "==================================================\n",
            "2461\n",
            "[' = Homarus gammarus = ', ' Homarus gammarus , known as the European lobster or common lobster , is a species of <unk> lobster from the eastern Atlantic Ocean , Mediterranean Sea and parts of the Black Sea . It is closely related to the American lobster , H. americanus . It may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . In life , the lobsters are blue , only becoming \" lobster red \" on cooking . Mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into <unk> larvae . Homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the British Isles . ', ' = = Description = = ', ' Homarus gammarus is a large <unk> , with a body length up to 60 centimetres ( 24 in ) and weighing up to 5 – 6 kilograms ( 11 – 13 lb ) , although the lobsters caught in lobster pots are usually 23 – 38 cm ( 9 – 15 in ) long and weigh 0 @.@ 7 – 2 @.@ 2 kg ( 1 @.@ 5 – 4 @.@ 9 lb ) . Like other crustaceans , lobsters have a hard <unk> which they must shed in order to grow , in a process called <unk> ( <unk> ) . This may occur several times a year for young lobsters , but decreases to once every 1 – 2 years for larger animals . ', ' The first pair of <unk> is armed with a large , asymmetrical pair of claws . The larger one is the \" <unk> \" , and has rounded <unk> used for crushing prey ; the other is the \" cutter \" , which has sharp inner edges , and is used for holding or tearing the prey . Usually , the left claw is the <unk> , and the right is the cutter . ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text cleaning\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
        "\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "train_texts = [clean_text(t) for t in train_texts]\n",
        "test_texts = [clean_text(t) for t in test_texts]\n",
        "valid_texts = [clean_text(t) for t in valid_texts]\n",
        "\n",
        "print(train_texts[:5])\n",
        "print(test_texts[:5])\n",
        "print(valid_texts[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45m1-m1xjgj-",
        "outputId": "973bb82d-d205-45ac-b91d-d475cdab9827"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['valkyria chronicles iii', 'senj no valkyria 3 unk chronicles japanese 3 lit valkyria of the battlefield 3 commonly referred to as valkyria chronicles iii outside japan is a tactical role playing video game developed by sega and mediavision for the playstation portable released in january 2011 in japan it is the third game in the valkyria series unk the same fusion of tactical and real time gameplay as its predecessors the story runs parallel to the first game and follows the nameless a penal military unit serving the nation of gallia during the second europan war who perform secret black operations and are pitted against the imperial unit unk raven', 'the game began development in 2010 carrying over a large portion of the work done on valkyria chronicles ii while it retained the standard features of the series it also underwent multiple adjustments such as making the game more unk for series newcomers character designer unk honjou and composer hitoshi sakimoto both returned from previous entries along with valkyria chronicles ii director takeshi ozawa a large team of writers handled the script the game s opening theme was sung by may n', 'it met with positive sales in japan and was praised by both japanese and western critics after release it received downloadable content along with an expanded edition in november of that year it was also adapted into manga and an original video animation series due to low sales of valkyria chronicles ii valkyria chronicles iii was not localized but a fan translation compatible with the game s expanded edition was released in 2014 mediavision would return to the franchise with the development of valkyria azure revolution for the playstation 4', 'gameplay']\n",
            "['robert unk', 'robert unk is an english film television and theatre actor he had a guest starring role on the television series the bill in 2000 this was followed by a starring role in the play herons written by simon stephens which was performed in 2001 at the royal court theatre he had a guest role in the television series judge john unk in 2002 in 2004 unk landed a role as craig in the episode teddy s story of the television series the long firm he starred alongside actors mark strong and derek jacobi he was cast in the 2005 theatre productions of the philip ridley play mercury fur which was performed at the drum theatre in plymouth and the unk unk factory in london he was directed by john unk and starred alongside ben unk shane unk harry kent fraser unk sophie stanton and dominic hall', 'in 2006 unk starred alongside unk in the play unk written by mark unk he appeared on a 2006 episode of the television series doctors followed by a role in the 2007 theatre production of how to curse directed by unk unk how to curse was performed at bush theatre in the london borough of unk and fulham unk starred in two films in 2008 unk unk by filmmaker paris unk and unk punch directed by unk blackburn in may 2008 unk made a guest appearance on a two part episode arc of the television series waking the dead followed by an appearance on the television series unk in november 2008 he had a recurring role in ten episodes of the television series unk in 2010 as unk fletcher unk starred in the 2011 film unk directed by paris unk', 'career', '2000 2005']\n",
            "['homarus gammarus', 'homarus gammarus known as the european lobster or common lobster is a species of unk lobster from the eastern atlantic ocean mediterranean sea and parts of the black sea it is closely related to the american lobster h americanus it may grow to a length of 60 cm 24 in and a mass of 6 kilograms 13 lb and bears a conspicuous pair of claws in life the lobsters are blue only becoming lobster red on cooking mating occurs in the summer producing eggs which are carried by the females for up to a year before hatching into unk larvae homarus gammarus is a highly esteemed food and is widely caught using lobster pots mostly around the british isles', 'description', 'homarus gammarus is a large unk with a body length up to 60 centimetres 24 in and weighing up to 5 6 kilograms 11 13 lb although the lobsters caught in lobster pots are usually 23 38 cm 9 15 in long and weigh 0 7 2 2 kg 1 5 4 9 lb like other crustaceans lobsters have a hard unk which they must shed in order to grow in a process called unk unk this may occur several times a year for young lobsters but decreases to once every 1 2 years for larger animals', 'the first pair of unk is armed with a large asymmetrical pair of claws the larger one is the unk and has rounded unk used for crushing prey the other is the cutter which has sharp inner edges and is used for holding or tearing the prey usually the left claw is the unk and the right is the cutter']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max(len(seq) for seq in train_texts)\n",
        "max_length\n",
        "# this is too many so we will use 300 as a max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKZ-Wo6_ra27",
        "outputId": "06135f12-05ac-4e86-c950-f8eb5903a4b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3657"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Tokeization`"
      ],
      "metadata": {
        "id": "ouV5Le4gnh_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct tokenizer\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<UNK>\")\n",
        "\n",
        "# fit the tokenizer on training data\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "\n",
        "# tokenize train,test,and valid texts\n",
        "train_tokenized = tokenizer.texts_to_sequences(train_texts)\n",
        "test_tokenized = tokenizer.texts_to_sequences(test_texts)\n",
        "valid_tokenized = tokenizer.texts_to_sequences(valid_texts)\n",
        "\n",
        "#show a sample\n",
        "print(train_tokenized[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbkzJnA4cOzf",
        "outputId": "e0b5bb44-8788-419a-d1e8-bca60ff364b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3768, 3831, 857], [18088, 76, 3768, 81, 4, 3831, 757, 81, 6066, 3768, 3, 2, 4989, 81, 1810, 986, 7, 11, 3768, 3831, 857, 611, 952, 17, 8, 5636, 285, 556, 219, 60, 433, 16, 12881, 5, 1, 14, 2, 1736, 5531, 147, 6, 233, 341, 6, 952, 18, 17, 2, 224, 60, 6, 2, 3768, 86, 4, 2, 148, 4362, 3, 5636, 5, 708, 51, 2064, 11, 36, 6902, 2, 319, 1057, 3168, 7, 2, 31, 60, 5, 1665, 2, 10766, 8, 18089, 299, 1037, 2042, 2, 1666, 3, 18090, 49, 2, 88, 1, 100, 45, 1906, 1617, 275, 580, 5, 28, 12882, 113, 2, 2280, 1037, 4, 13867], [2, 60, 127, 354, 6, 284, 3210, 58, 8, 175, 1710, 3, 2, 130, 1155, 10, 3768, 3831, 289, 59, 18, 3211, 2, 1148, 562, 3, 2, 86, 18, 37, 4281, 1811, 18091, 82, 11, 390, 2, 60, 54, 4, 14, 86, 18092, 265, 3707, 4, 1, 5, 2998, 1, 18093, 92, 417, 19, 463, 11411, 155, 15, 3768, 3831, 289, 520, 16354, 1, 8, 175, 149, 3, 1114, 3832, 2, 1589, 2, 60, 12, 639, 1041, 9, 3543, 16, 68, 1626], [18, 767, 15, 907, 1418, 6, 952, 5, 9, 714, 16, 92, 757, 5, 405, 502, 38, 306, 18, 194, 5905, 1812, 155, 15, 24, 2114, 1296, 6, 255, 3, 13, 78, 18, 9, 37, 2501, 53, 3315, 5, 24, 251, 219, 4074, 86, 183, 7, 466, 1418, 3, 3768, 3831, 289, 3768, 3831, 857, 9, 33, 9388, 32, 8, 2873, 3951, 10254, 15, 2, 60, 12, 2114, 1296, 9, 147, 6, 652, 1, 55, 526, 7, 2, 2912, 15, 2, 354, 3, 3768, 1, 1839, 14, 2, 1736, 109], [2064]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `Input/Target Sequence`"
      ],
      "metadata": {
        "id": "g28XL2mIq4AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a function to make input & target sequence\n",
        "def create_input_target(sequences, seq_len=SEQ_LEN):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for seq in sequences:\n",
        "        if len(seq) <= seq_len:\n",
        "            continue\n",
        "\n",
        "        for i in range(len(seq) - seq_len):\n",
        "            inputs.append(seq[i:i+seq_len])\n",
        "            targets.append(seq[i+seq_len])\n",
        "\n",
        "    return np.array(inputs), np.array(targets)\n",
        "\n",
        "x_train, y_train = create_input_target(train_tokenized, SEQ_LEN)\n",
        "x_valid, y_valid = create_input_target(valid_tokenized, SEQ_LEN)\n",
        "x_test, y_test   = create_input_target(test_tokenized, SEQ_LEN)\n",
        "print(\"Train inputs shape:\", x_train.shape)\n",
        "print(\"Train targets shape:\", y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBvhI-j5q3q_",
        "outputId": "04338622-3068-4a14-b3a9-9274847dddf6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train inputs shape: (1568571, 10)\n",
            "Train targets shape: (1568571,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN, GRU & LSTM phase (text generation)"
      ],
      "metadata": {
        "id": "vVArCNLQX0t_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `simple RNN`"
      ],
      "metadata": {
        "id": "HLUvpCJ79U1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "GW3CECup4A-l",
        "outputId": "b12b6461-87b5-464c-9f73-b8edce8b81f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3657\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3657\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m12,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m3,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │       \u001b[38;5;34m660,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3657</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3657</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">660,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,235,456\u001b[0m (12.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,235,456</span> (12.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,235,456\u001b[0m (12.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,235,456</span> (12.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Building the simple RNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=EMBED_DIM, input_shape=(max_length,)),\n",
        "    SimpleRNN(64 ,return_sequences=True),\n",
        "    SimpleRNN(32),\n",
        "    Dense(VOCAB_SIZE, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MphdrfbvDyzt",
        "outputId": "c8c92e57-2a22-4032-8d18-a51d0c9743c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m6128/6128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1108s\u001b[0m 180ms/step - accuracy: 0.0948 - loss: 7.1443 - val_accuracy: 0.1309 - val_loss: 6.4236\n",
            "Epoch 2/3\n",
            "\u001b[1m6128/6128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1111s\u001b[0m 181ms/step - accuracy: 0.1262 - loss: 6.5852 - val_accuracy: 0.1372 - val_loss: 6.3755\n",
            "Epoch 3/3\n",
            "\u001b[1m3313/6128\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m7:48\u001b[0m 166ms/step - accuracy: 0.1292 - loss: 6.4749"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to test the model\n",
        "def generate_text1(seed_text, num_words=3):\n",
        "    text = seed_text\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        seq = tokenizer.texts_to_sequences([text])[0]\n",
        "        seq = pad_sequences([seq], maxlen=max_length)\n",
        "\n",
        "        preds = model.predict(seq, verbose=0)\n",
        "        next_word_id = preds.argmax()\n",
        "\n",
        "        next_word = tokenizer.index_word.get(next_word_id, \"\")\n",
        "        text += \" \" + next_word\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "Dc5kuhbiW0AP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trying the model\n",
        "print(generate_text1(\"deep learnin went\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZd648DPYOp-",
        "outputId": "c30b3964-019c-4e3a-999d-b86ff6aa784d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep learnin went to the unk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `LSTM & GRU (Text generation)`"
      ],
      "metadata": {
        "id": "_bUNIUspv8W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the LSTM & GRU model\n",
        "model_v2 = Sequential([\n",
        "    Embedding(input_dim=VOCAB_SIZE, output_dim=EMBED_DIM, input_shape=(max_length,)),\n",
        "    LSTM(64 ,dropout=0.2 ,return_sequences=True),\n",
        "    GRU(32, dropout=0.2),\n",
        "    Dense(VOCAB_SIZE, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "eKmf1a6GYWIn",
        "outputId": "63ba99bf-9f18-4a0c-a263-1e265656b8fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3657\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │     \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3657\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m12,352\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m3,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │       \u001b[38;5;34m660,000\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3657</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3657</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">660,000</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,235,456\u001b[0m (12.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,235,456</span> (12.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,235,456\u001b[0m (12.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,235,456</span> (12.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v2.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRVZmoqlyXmh",
        "outputId": "2e6d9443-c87e-45c7-f1aa-549f8d86d0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m6128/6128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1389s\u001b[0m 227ms/step - accuracy: 0.0744 - loss: 7.5057 - val_accuracy: 0.0776 - val_loss: 7.1922\n",
            "Epoch 2/3\n",
            "\u001b[1m6128/6128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1317s\u001b[0m 215ms/step - accuracy: 0.0829 - loss: 7.2840 - val_accuracy: 0.1340 - val_loss: 6.3774\n",
            "Epoch 3/3\n",
            "\u001b[1m6128/6128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1339s\u001b[0m 214ms/step - accuracy: 0.1200 - loss: 6.5774 - val_accuracy: 0.1421 - val_loss: 6.1957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to test the model\n",
        "def generate_text2(seed_text, num_words=3):\n",
        "    text = seed_text\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        seq = tokenizer.texts_to_sequences([text])[0]\n",
        "        seq = pad_sequences([seq], maxlen=max_length)\n",
        "\n",
        "        preds = model_v2.predict(seq, verbose=0)\n",
        "        next_word_id = preds.argmax()\n",
        "\n",
        "        next_word = tokenizer.index_word.get(next_word_id, \"\")\n",
        "        text += \" \" + next_word\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "3l-bMVRPynck"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trying the model\n",
        "print(generate_text2(\"obama is man\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqavkhM4Fgn0",
        "outputId": "61e8e0f2-5b1a-4db2-a070-ebaa329426f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "obama is man routes routes politicians\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "End of phase 1"
      ],
      "metadata": {
        "id": "-JJRvnYzbjRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------"
      ],
      "metadata": {
        "id": "5RBvuEovbXuD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "On-AZVWCFkKO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}